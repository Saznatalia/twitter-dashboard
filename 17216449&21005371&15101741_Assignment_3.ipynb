{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2130747b",
   "metadata": {},
   "source": [
    "# Assignment 3 Visual Network Analysis of Twitter Hashtags\n",
    "\n",
    "### Objective: \n",
    "\n",
    "Build an interactive app that will allow a user to input a hashtag and returns the network visualization of hashtags connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc5566d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8438d780db76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload_plotlyjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "import functions\n",
    "from textblob import TextBlob, Word, Blobber\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.taggers import NLTKTagger\n",
    "from notebook_functions import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd01a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas options\n",
    "pd.set_option('max_columns', 25)\n",
    "pd.set_option('max_rows',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e163d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs notebook with stored API keys\n",
    "%run ./keys.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "rcParams['font.size'] = 20\n",
    "rcParams['axes.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentification to access twitter API\n",
    "api = initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015449ac",
   "metadata": {},
   "source": [
    "After importing all necessary libraries and completing the authentification process to access Twitter API, prompt for user input of a hashtag wishing to be explored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04010c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input\n",
    "no_of_tweets = 100\n",
    "query = input(\"Please enter keyword or hashtag to search: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.DataFrame(columns = [\"tag\",\"sentiment\"])\n",
    "edge_df = pd.DataFrame(columns = [\"tag\",\"associated_tag\"])\n",
    "place_df = pd.DataFrame(columns = [\"tweet\", \"place\"])\n",
    "sentiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce294a9",
   "metadata": {},
   "source": [
    "Render through JSON file and save necessary information to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf90222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweets \n",
    "public_tweets = tw.Cursor(api.search, q=\"{}\".format(query),show_user = True,tweet_mode=\"extended\").items(100)\n",
    "\n",
    "# Save tweeets into data frames\n",
    "for tweet in public_tweets:\n",
    "    place_df = place_df.append({\"tweet\":tweet.full_text,\"place\":tweet.user.location},ignore_index = True)\n",
    "    sentiments.append({'text': tweet.full_text, 'date': tweet.created_at, 'sentiment_TB': TextBlob(tweet.full_text).polarity})\n",
    "    try:       \n",
    "        temp_tags = []\n",
    "        for i,tag in enumerate(tweet.entities.get('hashtags')):\n",
    "            temp_tags.append(tag[\"text\"])\n",
    "            node_df = node_df.append({\"tag\":tag[\"text\"],\"sentiment\":TextBlob(tweet.full_text).polarity},ignore_index=True)\n",
    "        #print(temp_tags)\n",
    "        res = list(itertools.combinations(temp_tags, 2))\n",
    "        if res != []:\n",
    "            for pair in res:\n",
    "                edge_df = edge_df.append({\"tag\":pair[0],\"associated_tag\":pair[1]},ignore_index=True)\n",
    "        \n",
    "    except Exception as inst:\n",
    "        print(type(inst))    # the exception instance\n",
    "        print(inst.args)     # arguments stored in .args\n",
    "        print(inst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b551ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame.from_dict(sentiments)\n",
    "tweets_df['text'] = clean_tweets(tweets_df['text'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311189a",
   "metadata": {},
   "source": [
    "Using VADER analysis, analyze the tweets and save results to the data frame, compare with TextBlob polarity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3434e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(tweets_df['text'].shape[0]):\n",
    "    compound = SentimentIntensityAnalyzer().polarity_scores(tweets_df.text[i])['compound']\n",
    "    positive = SentimentIntensityAnalyzer().polarity_scores(tweets_df.text[i])['pos']\n",
    "    neutral = SentimentIntensityAnalyzer().polarity_scores(tweets_df.text[i])['neu']\n",
    "    negative = SentimentIntensityAnalyzer().polarity_scores(tweets_df.text[i])['neg']\n",
    "    scores.append({\n",
    "        'compound': compound,\n",
    "        'positive': positive,\n",
    "        'neutral': neutral,\n",
    "        'negative': negative\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb144241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, row in tweets_df.iterrows():\n",
    "    tweets_df.at[i, \"analysis\"] = analyze(row.text)   \n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e124f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame.from_dict(scores)\n",
    "combo_df = tweets_df.join(scores_df)\n",
    "combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d817105",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = node_df.groupby([\"tag\"]).agg(\"count\")\n",
    "node_sent = node_df.groupby([\"tag\"]).agg(\"mean\")\n",
    "node_with_count_dict = {}\n",
    "for row in node_count.iterrows():\n",
    "    node_with_count_dict[row[0]] = row[1].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca7b54",
   "metadata": {},
   "source": [
    "Analyze the sentiment for a certain hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02990816",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentiment = node_df.groupby(by='tag').mean()\n",
    "avg_sentiment[avg_sentiment[\"sentiment\"] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82ba7f",
   "metadata": {},
   "source": [
    "Find the top 5 locations twitter came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fc199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aecea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_df[\"place\"].replace(\"\",np.nan, inplace = True)\n",
    "x = place_df.dropna().groupby(\"place\").count().sort_values(by=\"tweet\", ascending=False).head()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54092f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_with_sent_dict = {}\n",
    "for row in node_sent.iterrows():\n",
    "    node_with_sent_dict[row[0]] = row[1].values[0]\n",
    "edge_count = edge_df.groupby(['tag','associated_tag']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for i in node_with_count_dict.keys():\n",
    "    G.add_node(i, count = node_with_count_dict[i], sentiment = node_with_sent_dict[i])\n",
    "for i,j in edge_df.iterrows():\n",
    "    G.add_edges_from([(j[\"tag\"],j[\"associated_tag\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, k=0.1, iterations=50)\n",
    "for n, p in pos.items():\n",
    "    G.nodes[n]['pos'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_trace = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    line=dict(width=0.5,color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = G.nodes[edge[0]]['pos']\n",
    "    x1, y1 = G.nodes[edge[1]]['pos']\n",
    "    edge_trace['x'] += tuple([x0, x1, None])\n",
    "    edge_trace['y'] += tuple([y0, y1, None])\n",
    "    \n",
    "node_trace = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    text=[],\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='Viridis',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=[],\n",
    "        colorbar=dict(\n",
    "            thickness=10,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line=dict(width=0)))\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_trace['x'] += tuple([x])\n",
    "    node_trace['y'] += tuple([y])\n",
    "    node_trace['marker']['color']+=tuple([G.nodes()[node]['sentiment']])\n",
    "    node_trace['marker']['size'] += tuple([15 + G.nodes()[node]['count']])\n",
    "    node_trace['text'] += tuple(['<b>' + node + ' count is {}, avg sentiment is {}</b>'.format(G.nodes()[node]['count'],G.nodes()[node]['sentiment'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Twitter hashtags of {}'.format(query),\n",
    "                titlefont=dict(size=16),\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"Tweets\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\") ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = tweets_df.analysis.hist(bins=5)\n",
    "# plt.title(\"Tweets Sentiment\", alpha=0.5)\n",
    "# plt.grid(False)\n",
    "# plt.xlabel('Tweets', alpha=0.5)\n",
    "# plt.ylabel(\"Percentage, %\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = tweets_df.analysis.unique()\n",
    "plt.hist([tweets_df.loc[tweets_df.analysis == x, 'analysis'] for x in sentiments], bins=3)\n",
    "plt.xlabel('Tweets', alpha=0.5)\n",
    "plt.ylabel(\"Percentage, %\", alpha=0.5)\n",
    "plt.title(\"Tweets sentiment\", alpha=0.6)\n",
    "plt.legend(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd26743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def word_cloud(wd_list):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    all_words = ' '.join([text for text in wd_list])\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        width=1600,\n",
    "        height=800,\n",
    "        random_state=1,\n",
    "        colormap='jet',\n",
    "        max_words=80,\n",
    "        max_font_size=200).generate(all_words)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\");\n",
    "word_cloud(tweets_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-relation",
   "metadata": {},
   "source": [
    "# Summary and Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-yemen",
   "metadata": {},
   "source": [
    "We found the dashboard to have both strengths and limitations, in terms of being a useful analytical tool. These are summarised below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-block",
   "metadata": {},
   "source": [
    "## Strengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-script",
   "metadata": {},
   "source": [
    "* The network graph is an effective tool for displaying linkages between different hashtags and groups of hashtags. Encoding of additional features using size and color allows the user to quickly determine the significance of a hashtag within the broader context.\n",
    "* Interactive features assist the user in exploring the data.\n",
    "* Through analysis of the network graph and statistical displays, it is possible to determine general sentiment associated with a search topic.\n",
    "* The dashboard could be used to determine which hashtags a twitter user could add to a tweet in order to increase engagement on a particular topic.\n",
    "* The dashboard could be used to determine a groups support for one topic, based on their attitude and interest toward another topic. Without the network visualisation, it may not not be obvious that these two topics are somehow related. This understanding would be useful in a variety of social, business or political contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-aluminum",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-protein",
   "metadata": {},
   "source": [
    "* The average sentiment of tweets associated with a given hashtag tends to be close to 0. This could be a problem when a hashtag is polarising and theaverage of the highly poistive and highly negative sentiment is neutral, which is not an accurate representation.\n",
    "* When displaying data associated with a large number of tweets (>1000 approx.), the visual tool becomes rather overwhelming and difficult to make sense of. Having the ability to filter hashtags that have appeared less than a certain number of times in a search could be a potential solution for effectively visualising larger amounts of data. \n",
    "* Some tweets included many hashtags that are related to a similar topic. Relationships between these hashtags tend to clutter teh display, rather than drawing links between disparate ideas (like we hypothesised).\n",
    "* Accurate location information is not available for all tweets, limiting the effectiveness of location based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
